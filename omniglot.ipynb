{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install Augmentor\\n!pip install pillow\\n!pip install pandas\\n!pip install matplotlib\\n!pip install numpy\\n!pip install keras\\n!unzip ./python/images_background.zip\\n!unzip ./python/images_background_small1.zip\\n!unzip ./python/images_background_small2.zip\\n!unzip ./python/images_evaluation.zip\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install Augmentor\n",
    "!pip install pillow\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install keras\n",
    "!unzip ./python/images_background.zip\n",
    "!unzip ./python/images_background_small1.zip\n",
    "!unzip ./python/images_background_small2.zip\n",
    "!unzip ./python/images_evaluation.zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from load_data import load_directory, train_gen, val_gen, quiz_models, LossTracker\n",
    "from build_models import make_convnet, make_capsnet, train_convnet, train_capsnet, plot_history\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "directory = './images_evaluation/Angelic/'\n",
    "train, test, labels = load_directory(directory)\n",
    "loss_tracker = LossTracker()\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=380) #Use the entire validation set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "n_class = len(labels)\n",
    "routings = 3\n",
    "reconstruction_loss = .392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 105, 105, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 97, 97, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 93, 93, 128)       204928    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 93, 93, 128)       0         \n",
      "_________________________________________________________________\n",
      "maxp1 (MaxPooling2D)         (None, 46, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 45, 45, 128)       65664     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 44, 44, 256)       131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 44, 44, 256)       0         \n",
      "_________________________________________________________________\n",
      "maxp2 (MaxPooling2D)         (None, 22, 22, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 21, 21, 256)       262400    \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 20, 20, 512)       524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "maxp3 (MaxPooling2D)         (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 9, 9, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "conv8 (Conv2D)               (None, 8, 8, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "maxp4 (MaxPooling2D)         (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv9 (Conv2D)               (None, 3, 3, 1024)        4195328   \n",
      "_________________________________________________________________\n",
      "conv10 (Conv2D)              (None, 2, 2, 2048)        8390656   \n",
      "_________________________________________________________________\n",
      "conv11 (Conv2D)              (None, 1, 1, 2368)        19401024  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2368)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2368)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              9703424   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 50,762,452\n",
      "Trainable params: 50,762,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnet = make_convnet(input_shape, n_class, width=64, dropout=.5)\n",
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/200\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 2.9966 - categorical_accuracy: 0.0525 - val_loss: 2.9957 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.05000, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.99569, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.9951 - categorical_accuracy: 0.0510 - val_loss: 2.9957 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.05000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.99569\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.9955 - categorical_accuracy: 0.0470 - val_loss: 2.9957 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.05000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.99569\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2.9951 - categorical_accuracy: 0.0575 - val_loss: 2.9956 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.05000\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.99569 to 2.99563, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2.9941 - categorical_accuracy: 0.0605 - val_loss: 2.9955 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy did not improve from 0.05000\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.99563 to 2.99547, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.9915 - categorical_accuracy: 0.0620 - val_loss: 2.9953 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.05000\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.99547 to 2.99528, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.9876 - categorical_accuracy: 0.0550 - val_loss: 2.9948 - val_categorical_accuracy: 0.0789\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.05000 to 0.07895, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.99528 to 2.99475, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2.9840 - categorical_accuracy: 0.0615 - val_loss: 2.9935 - val_categorical_accuracy: 0.0500\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.07895\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.99475 to 2.99347, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.9678 - categorical_accuracy: 0.0775 - val_loss: 2.9879 - val_categorical_accuracy: 0.1579\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.07895 to 0.15789, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.99347 to 2.98795, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.8953 - categorical_accuracy: 0.0935 - val_loss: 2.9641 - val_categorical_accuracy: 0.1947\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.15789 to 0.19474, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.98795 to 2.96411, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 2.6345 - categorical_accuracy: 0.1640 - val_loss: 2.8919 - val_categorical_accuracy: 0.2105\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy improved from 0.19474 to 0.21053, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.96411 to 2.89191, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2.2034 - categorical_accuracy: 0.2760 - val_loss: 2.8343 - val_categorical_accuracy: 0.2605\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.21053 to 0.26053, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.89191 to 2.83430, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 1.7337 - categorical_accuracy: 0.4475 - val_loss: 2.7392 - val_categorical_accuracy: 0.3132\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.26053 to 0.31316, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.83430 to 2.73924, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 1.2256 - categorical_accuracy: 0.6260 - val_loss: 2.6832 - val_categorical_accuracy: 0.3737\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.31316 to 0.37368, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.73924 to 2.68317, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.8967 - categorical_accuracy: 0.7595 - val_loss: 2.5292 - val_categorical_accuracy: 0.4237\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.37368 to 0.42368, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.68317 to 2.52922, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.7224 - categorical_accuracy: 0.8240 - val_loss: 2.5149 - val_categorical_accuracy: 0.4342\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.42368 to 0.43421, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.52922 to 2.51486, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.6234 - categorical_accuracy: 0.8450 - val_loss: 2.5123 - val_categorical_accuracy: 0.4342\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.43421\n",
      "\n",
      "Epoch 00017: val_loss improved from 2.51486 to 2.51226, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.5854 - categorical_accuracy: 0.8620 - val_loss: 2.5371 - val_categorical_accuracy: 0.4395\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.43421 to 0.43947, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.51226\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.5822 - categorical_accuracy: 0.8595 - val_loss: 2.5111 - val_categorical_accuracy: 0.4789\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy improved from 0.43947 to 0.47895, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.51226 to 2.51105, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.5372 - categorical_accuracy: 0.8675 - val_loss: 2.5000 - val_categorical_accuracy: 0.4895\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.47895 to 0.48947, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 2.51105 to 2.49999, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4996 - categorical_accuracy: 0.8765 - val_loss: 2.5370 - val_categorical_accuracy: 0.5263\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.48947 to 0.52632, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00021: val_loss did not improve from 2.49999\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.5419 - categorical_accuracy: 0.8620 - val_loss: 2.4857 - val_categorical_accuracy: 0.5211\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.52632\n",
      "\n",
      "Epoch 00022: val_loss improved from 2.49999 to 2.48569, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4788 - categorical_accuracy: 0.8790 - val_loss: 2.4856 - val_categorical_accuracy: 0.5263\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.52632\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.48569 to 2.48560, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4760 - categorical_accuracy: 0.8760 - val_loss: 2.5087 - val_categorical_accuracy: 0.5447\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.52632 to 0.54474, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.48560\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4964 - categorical_accuracy: 0.8790 - val_loss: 2.4101 - val_categorical_accuracy: 0.5447\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.54474\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.48560 to 2.41006, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4024 - categorical_accuracy: 0.8835 - val_loss: 2.4174 - val_categorical_accuracy: 0.5316\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.54474\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.41006\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4041 - categorical_accuracy: 0.8955 - val_loss: 2.4237 - val_categorical_accuracy: 0.5632\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy improved from 0.54474 to 0.56316, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.41006\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.4006 - categorical_accuracy: 0.8960 - val_loss: 2.3957 - val_categorical_accuracy: 0.5684\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy improved from 0.56316 to 0.56842, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.41006 to 2.39570, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4488 - categorical_accuracy: 0.8760 - val_loss: 2.3806 - val_categorical_accuracy: 0.5737\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy improved from 0.56842 to 0.57368, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.39570 to 2.38057, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3815 - categorical_accuracy: 0.8940 - val_loss: 2.3603 - val_categorical_accuracy: 0.5816\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.57368 to 0.58158, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.38057 to 2.36026, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4081 - categorical_accuracy: 0.8865 - val_loss: 2.3898 - val_categorical_accuracy: 0.5789\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.58158\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.36026\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4048 - categorical_accuracy: 0.8855 - val_loss: 2.3542 - val_categorical_accuracy: 0.5789\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.58158\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.36026 to 2.35415, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4044 - categorical_accuracy: 0.8820 - val_loss: 2.3372 - val_categorical_accuracy: 0.5737\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.58158\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.35415 to 2.33716, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4049 - categorical_accuracy: 0.8845 - val_loss: 2.3132 - val_categorical_accuracy: 0.6211\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy improved from 0.58158 to 0.62105, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.33716 to 2.31316, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3643 - categorical_accuracy: 0.8910 - val_loss: 2.2653 - val_categorical_accuracy: 0.5921\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.62105\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.31316 to 2.26530, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3632 - categorical_accuracy: 0.8930 - val_loss: 2.2933 - val_categorical_accuracy: 0.5921\n",
      "\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.62105\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.26530\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.4001 - categorical_accuracy: 0.8835 - val_loss: 2.2795 - val_categorical_accuracy: 0.6132\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.62105\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.26530\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3749 - categorical_accuracy: 0.8815 - val_loss: 2.2201 - val_categorical_accuracy: 0.6342\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy improved from 0.62105 to 0.63421, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.26530 to 2.22014, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3477 - categorical_accuracy: 0.8955 - val_loss: 2.2378 - val_categorical_accuracy: 0.6263\n",
      "\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.63421\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.22014\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3282 - categorical_accuracy: 0.8985 - val_loss: 2.2038 - val_categorical_accuracy: 0.6211\n",
      "\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.63421\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.22014 to 2.20380, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3461 - categorical_accuracy: 0.8920 - val_loss: 2.2089 - val_categorical_accuracy: 0.6237\n",
      "\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.63421\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.20380\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3270 - categorical_accuracy: 0.9000 - val_loss: 2.1890 - val_categorical_accuracy: 0.6211\n",
      "\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.63421\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.20380 to 2.18899, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3376 - categorical_accuracy: 0.8985 - val_loss: 2.2168 - val_categorical_accuracy: 0.6263\n",
      "\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.63421\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.18899\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3351 - categorical_accuracy: 0.9060 - val_loss: 2.1913 - val_categorical_accuracy: 0.6395\n",
      "\n",
      "Epoch 00044: val_categorical_accuracy improved from 0.63421 to 0.63947, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.18899\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3578 - categorical_accuracy: 0.8930 - val_loss: 2.1495 - val_categorical_accuracy: 0.6447\n",
      "\n",
      "Epoch 00045: val_categorical_accuracy improved from 0.63947 to 0.64474, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.18899 to 2.14951, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3027 - categorical_accuracy: 0.9025 - val_loss: 2.1363 - val_categorical_accuracy: 0.6474\n",
      "\n",
      "Epoch 00046: val_categorical_accuracy improved from 0.64474 to 0.64737, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.14951 to 2.13630, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3022 - categorical_accuracy: 0.9080 - val_loss: 2.1312 - val_categorical_accuracy: 0.6711\n",
      "\n",
      "Epoch 00047: val_categorical_accuracy improved from 0.64737 to 0.67105, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.13630 to 2.13123, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3149 - categorical_accuracy: 0.9050 - val_loss: 2.1302 - val_categorical_accuracy: 0.6632\n",
      "\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.67105\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.13123 to 2.13016, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.3120 - categorical_accuracy: 0.9035 - val_loss: 2.1055 - val_categorical_accuracy: 0.6737\n",
      "\n",
      "Epoch 00049: val_categorical_accuracy improved from 0.67105 to 0.67368, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.13016 to 2.10553, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2909 - categorical_accuracy: 0.9085 - val_loss: 2.0766 - val_categorical_accuracy: 0.6579\n",
      "\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.67368\n",
      "\n",
      "Epoch 00050: val_loss improved from 2.10553 to 2.07660, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2804 - categorical_accuracy: 0.9135 - val_loss: 2.0940 - val_categorical_accuracy: 0.6816\n",
      "\n",
      "Epoch 00051: val_categorical_accuracy improved from 0.67368 to 0.68158, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.07660\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2825 - categorical_accuracy: 0.9080 - val_loss: 2.0857 - val_categorical_accuracy: 0.6711\n",
      "\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.68158\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.07660\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2862 - categorical_accuracy: 0.9095 - val_loss: 2.0612 - val_categorical_accuracy: 0.6684\n",
      "\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.68158\n",
      "\n",
      "Epoch 00053: val_loss improved from 2.07660 to 2.06122, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.2493 - categorical_accuracy: 0.9190 - val_loss: 2.0407 - val_categorical_accuracy: 0.7026\n",
      "\n",
      "Epoch 00054: val_categorical_accuracy improved from 0.68158 to 0.70263, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00054: val_loss improved from 2.06122 to 2.04068, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2677 - categorical_accuracy: 0.9150 - val_loss: 2.0728 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.70263\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.04068\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2766 - categorical_accuracy: 0.9135 - val_loss: 2.0094 - val_categorical_accuracy: 0.6921\n",
      "\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.70263\n",
      "\n",
      "Epoch 00056: val_loss improved from 2.04068 to 2.00938, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2411 - categorical_accuracy: 0.9210 - val_loss: 1.9926 - val_categorical_accuracy: 0.7158\n",
      "\n",
      "Epoch 00057: val_categorical_accuracy improved from 0.70263 to 0.71579, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00057: val_loss improved from 2.00938 to 1.99260, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - categorical_accuracy: 0.9190 - val_loss: 2.0042 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.99260\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2912 - categorical_accuracy: 0.9110 - val_loss: 2.0775 - val_categorical_accuracy: 0.6895\n",
      "\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.99260\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2499 - categorical_accuracy: 0.9180 - val_loss: 2.0033 - val_categorical_accuracy: 0.6737\n",
      "\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.99260\n",
      "Epoch 61/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2390 - categorical_accuracy: 0.9260 - val_loss: 1.9745 - val_categorical_accuracy: 0.6895\n",
      "\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.99260 to 1.97451, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 62/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2440 - categorical_accuracy: 0.9255 - val_loss: 2.0116 - val_categorical_accuracy: 0.7053\n",
      "\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.97451\n",
      "Epoch 63/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2308 - categorical_accuracy: 0.9275 - val_loss: 1.9548 - val_categorical_accuracy: 0.7079\n",
      "\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.97451 to 1.95481, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 64/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2641 - categorical_accuracy: 0.9120 - val_loss: 1.9559 - val_categorical_accuracy: 0.7158\n",
      "\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.95481\n",
      "Epoch 65/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2395 - categorical_accuracy: 0.9250 - val_loss: 1.9459 - val_categorical_accuracy: 0.7132\n",
      "\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.95481 to 1.94586, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 66/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2232 - categorical_accuracy: 0.9320 - val_loss: 1.9238 - val_categorical_accuracy: 0.7053\n",
      "\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.71579\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.94586 to 1.92381, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 67/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2552 - categorical_accuracy: 0.9155 - val_loss: 1.9906 - val_categorical_accuracy: 0.7184\n",
      "\n",
      "Epoch 00067: val_categorical_accuracy improved from 0.71579 to 0.71842, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.92381\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2375 - categorical_accuracy: 0.9205 - val_loss: 1.9795 - val_categorical_accuracy: 0.7105\n",
      "\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.71842\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.92381\n",
      "Epoch 69/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2059 - categorical_accuracy: 0.9360 - val_loss: 1.9291 - val_categorical_accuracy: 0.7237\n",
      "\n",
      "Epoch 00069: val_categorical_accuracy improved from 0.71842 to 0.72368, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.92381\n",
      "Epoch 70/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1802 - categorical_accuracy: 0.9400 - val_loss: 1.8999 - val_categorical_accuracy: 0.7421\n",
      "\n",
      "Epoch 00070: val_categorical_accuracy improved from 0.72368 to 0.74211, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.92381 to 1.89987, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 71/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2343 - categorical_accuracy: 0.9240 - val_loss: 1.9131 - val_categorical_accuracy: 0.7316\n",
      "\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.74211\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.89987\n",
      "Epoch 72/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2143 - categorical_accuracy: 0.9310 - val_loss: 1.9279 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00072: val_categorical_accuracy improved from 0.74211 to 0.74737, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.89987\n",
      "Epoch 73/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2107 - categorical_accuracy: 0.9300 - val_loss: 1.9262 - val_categorical_accuracy: 0.7316\n",
      "\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.74737\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.89987\n",
      "Epoch 74/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2163 - categorical_accuracy: 0.9335 - val_loss: 1.9040 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00074: val_categorical_accuracy improved from 0.74737 to 0.75263, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.89987\n",
      "Epoch 75/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2018 - categorical_accuracy: 0.9375 - val_loss: 1.9211 - val_categorical_accuracy: 0.7395\n",
      "\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.75263\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.89987\n",
      "Epoch 76/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2103 - categorical_accuracy: 0.9380 - val_loss: 1.9166 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.75263\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.89987\n",
      "Epoch 77/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2209 - categorical_accuracy: 0.9280 - val_loss: 1.9343 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00077: val_categorical_accuracy improved from 0.75263 to 0.75789, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.89987\n",
      "Epoch 78/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2015 - categorical_accuracy: 0.9350 - val_loss: 1.9029 - val_categorical_accuracy: 0.7342\n",
      "\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.89987\n",
      "Epoch 79/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1875 - categorical_accuracy: 0.9490 - val_loss: 1.8534 - val_categorical_accuracy: 0.7263\n",
      "\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.89987 to 1.85343, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 80/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2074 - categorical_accuracy: 0.9365 - val_loss: 1.8663 - val_categorical_accuracy: 0.7368\n",
      "\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.85343\n",
      "Epoch 81/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1908 - categorical_accuracy: 0.9385 - val_loss: 1.8619 - val_categorical_accuracy: 0.7342\n",
      "\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.85343\n",
      "Epoch 82/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1741 - categorical_accuracy: 0.9465 - val_loss: 1.8539 - val_categorical_accuracy: 0.7211\n",
      "\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.85343\n",
      "Epoch 83/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1624 - categorical_accuracy: 0.9525 - val_loss: 1.8084 - val_categorical_accuracy: 0.7447\n",
      "\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.85343 to 1.80837, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 84/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2080 - categorical_accuracy: 0.9325 - val_loss: 1.8316 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.80837\n",
      "Epoch 85/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1841 - categorical_accuracy: 0.9370 - val_loss: 1.8329 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.80837\n",
      "Epoch 86/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2025 - categorical_accuracy: 0.9385 - val_loss: 1.8440 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.80837\n",
      "Epoch 87/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2027 - categorical_accuracy: 0.9435 - val_loss: 1.8411 - val_categorical_accuracy: 0.7447\n",
      "\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.80837\n",
      "Epoch 88/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1787 - categorical_accuracy: 0.9485 - val_loss: 1.8067 - val_categorical_accuracy: 0.7395\n",
      "\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.80837 to 1.80668, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 89/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.2185 - categorical_accuracy: 0.9355 - val_loss: 1.8476 - val_categorical_accuracy: 0.7553\n",
      "\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.80668\n",
      "Epoch 90/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1772 - categorical_accuracy: 0.9450 - val_loss: 1.8486 - val_categorical_accuracy: 0.7553\n",
      "\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.75789\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.80668\n",
      "Epoch 91/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1749 - categorical_accuracy: 0.9475 - val_loss: 1.7884 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00091: val_categorical_accuracy improved from 0.75789 to 0.76316, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.80668 to 1.78843, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 92/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1928 - categorical_accuracy: 0.9430 - val_loss: 1.8079 - val_categorical_accuracy: 0.7447\n",
      "\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.76316\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.78843\n",
      "Epoch 93/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1590 - categorical_accuracy: 0.9530 - val_loss: 1.7453 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.76316\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.78843 to 1.74534, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1803 - categorical_accuracy: 0.9470 - val_loss: 1.8105 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00094: val_categorical_accuracy improved from 0.76316 to 0.77105, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.74534\n",
      "Epoch 95/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1775 - categorical_accuracy: 0.9445 - val_loss: 1.8264 - val_categorical_accuracy: 0.7421\n",
      "\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.74534\n",
      "Epoch 96/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1762 - categorical_accuracy: 0.9500 - val_loss: 1.8530 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.74534\n",
      "Epoch 97/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1765 - categorical_accuracy: 0.9480 - val_loss: 1.7965 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.74534\n",
      "Epoch 98/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1705 - categorical_accuracy: 0.9520 - val_loss: 1.8334 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.74534\n",
      "Epoch 99/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1606 - categorical_accuracy: 0.9510 - val_loss: 1.8143 - val_categorical_accuracy: 0.7553\n",
      "\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.74534\n",
      "Epoch 100/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1746 - categorical_accuracy: 0.9480 - val_loss: 1.7682 - val_categorical_accuracy: 0.7368\n",
      "\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.74534\n",
      "Epoch 101/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1402 - categorical_accuracy: 0.9565 - val_loss: 1.7479 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00101: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.74534\n",
      "Epoch 102/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1693 - categorical_accuracy: 0.9530 - val_loss: 1.7793 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00102: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.74534\n",
      "Epoch 103/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1629 - categorical_accuracy: 0.9490 - val_loss: 1.8004 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00103: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.74534\n",
      "Epoch 104/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1355 - categorical_accuracy: 0.9545 - val_loss: 1.7451 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00104: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00104: val_loss improved from 1.74534 to 1.74509, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 105/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1553 - categorical_accuracy: 0.9525 - val_loss: 1.7567 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00105: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.74509\n",
      "Epoch 106/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1495 - categorical_accuracy: 0.9580 - val_loss: 1.7721 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00106: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.74509\n",
      "Epoch 107/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1205 - categorical_accuracy: 0.9620 - val_loss: 1.7390 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00107: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00107: val_loss improved from 1.74509 to 1.73900, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 108/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1567 - categorical_accuracy: 0.9540 - val_loss: 1.7416 - val_categorical_accuracy: 0.7553\n",
      "\n",
      "Epoch 00108: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.73900\n",
      "Epoch 109/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1386 - categorical_accuracy: 0.9610 - val_loss: 1.7409 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00109: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.73900\n",
      "Epoch 110/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1480 - categorical_accuracy: 0.9525 - val_loss: 1.7477 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00110: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.73900\n",
      "Epoch 111/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1485 - categorical_accuracy: 0.9585 - val_loss: 1.7567 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00111: val_categorical_accuracy did not improve from 0.77105\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.73900\n",
      "Epoch 112/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1620 - categorical_accuracy: 0.9585 - val_loss: 1.7502 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00112: val_categorical_accuracy improved from 0.77105 to 0.77632, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.73900\n",
      "Epoch 113/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1454 - categorical_accuracy: 0.9555 - val_loss: 1.7669 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00113: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.73900\n",
      "Epoch 114/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1211 - categorical_accuracy: 0.9665 - val_loss: 1.7353 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00114: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00114: val_loss improved from 1.73900 to 1.73530, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 115/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1274 - categorical_accuracy: 0.9630 - val_loss: 1.7516 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00115: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.73530\n",
      "Epoch 116/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1648 - categorical_accuracy: 0.9475 - val_loss: 1.7824 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00116: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.73530\n",
      "Epoch 117/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1180 - categorical_accuracy: 0.9665 - val_loss: 1.7536 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00117: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.73530\n",
      "Epoch 118/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1285 - categorical_accuracy: 0.9600 - val_loss: 1.7435 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00118: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.73530\n",
      "Epoch 119/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1334 - categorical_accuracy: 0.9600 - val_loss: 1.7302 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00119: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00119: val_loss improved from 1.73530 to 1.73015, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 120/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1277 - categorical_accuracy: 0.9640 - val_loss: 1.7676 - val_categorical_accuracy: 0.7474\n",
      "\n",
      "Epoch 00120: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.73015\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1110 - categorical_accuracy: 0.9680 - val_loss: 1.7518 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00121: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.73015\n",
      "Epoch 122/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1176 - categorical_accuracy: 0.9660 - val_loss: 1.7437 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00122: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.73015\n",
      "Epoch 123/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1209 - categorical_accuracy: 0.9580 - val_loss: 1.7530 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00123: val_categorical_accuracy did not improve from 0.77632\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.73015\n",
      "Epoch 124/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1126 - categorical_accuracy: 0.9660 - val_loss: 1.7348 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00124: val_categorical_accuracy improved from 0.77632 to 0.78158, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.73015\n",
      "Epoch 125/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1241 - categorical_accuracy: 0.9645 - val_loss: 1.6848 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00125: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.73015 to 1.68479, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 126/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1156 - categorical_accuracy: 0.9660 - val_loss: 1.7493 - val_categorical_accuracy: 0.7526\n",
      "\n",
      "Epoch 00126: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.68479\n",
      "Epoch 127/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1340 - categorical_accuracy: 0.9615 - val_loss: 1.6903 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00127: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.68479\n",
      "Epoch 128/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0915 - categorical_accuracy: 0.9720 - val_loss: 1.6828 - val_categorical_accuracy: 0.7553\n",
      "\n",
      "Epoch 00128: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00128: val_loss improved from 1.68479 to 1.68282, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 129/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1166 - categorical_accuracy: 0.9670 - val_loss: 1.6849 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00129: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.68282\n",
      "Epoch 130/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1088 - categorical_accuracy: 0.9625 - val_loss: 1.6783 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00130: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00130: val_loss improved from 1.68282 to 1.67830, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 131/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0991 - categorical_accuracy: 0.9725 - val_loss: 1.6563 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00131: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00131: val_loss improved from 1.67830 to 1.65630, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 132/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0897 - categorical_accuracy: 0.9770 - val_loss: 1.6535 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00132: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00132: val_loss improved from 1.65630 to 1.65352, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 133/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1173 - categorical_accuracy: 0.9680 - val_loss: 1.6620 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00133: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1.65352\n",
      "Epoch 134/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1199 - categorical_accuracy: 0.9585 - val_loss: 1.7101 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00134: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1.65352\n",
      "Epoch 135/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1078 - categorical_accuracy: 0.9670 - val_loss: 1.6863 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00135: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1.65352\n",
      "Epoch 136/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1135 - categorical_accuracy: 0.9650 - val_loss: 1.6955 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00136: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1.65352\n",
      "Epoch 137/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1094 - categorical_accuracy: 0.9665 - val_loss: 1.6801 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00137: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1.65352\n",
      "Epoch 138/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1277 - categorical_accuracy: 0.9605 - val_loss: 1.7130 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00138: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1.65352\n",
      "Epoch 139/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1186 - categorical_accuracy: 0.9655 - val_loss: 1.7284 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00139: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1.65352\n",
      "Epoch 140/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0847 - categorical_accuracy: 0.9770 - val_loss: 1.6618 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00140: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1.65352\n",
      "Epoch 141/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1052 - categorical_accuracy: 0.9670 - val_loss: 1.6580 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00141: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1.65352\n",
      "Epoch 142/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1098 - categorical_accuracy: 0.9690 - val_loss: 1.6708 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00142: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1.65352\n",
      "Epoch 143/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0885 - categorical_accuracy: 0.9740 - val_loss: 1.6783 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00143: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1.65352\n",
      "Epoch 144/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0852 - categorical_accuracy: 0.9700 - val_loss: 1.6619 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00144: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1.65352\n",
      "Epoch 145/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0950 - categorical_accuracy: 0.9695 - val_loss: 1.6487 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00145: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00145: val_loss improved from 1.65352 to 1.64867, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 146/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0990 - categorical_accuracy: 0.9685 - val_loss: 1.6405 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00146: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00146: val_loss improved from 1.64867 to 1.64052, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 147/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1012 - categorical_accuracy: 0.9730 - val_loss: 1.6760 - val_categorical_accuracy: 0.7553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00147: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1.64052\n",
      "Epoch 148/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0732 - categorical_accuracy: 0.9770 - val_loss: 1.6408 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00148: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1.64052\n",
      "Epoch 149/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0899 - categorical_accuracy: 0.9725 - val_loss: 1.6523 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00149: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1.64052\n",
      "Epoch 150/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0951 - categorical_accuracy: 0.9720 - val_loss: 1.6508 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00150: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 1.64052\n",
      "Epoch 151/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.1009 - categorical_accuracy: 0.9685 - val_loss: 1.6764 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00151: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 1.64052\n",
      "Epoch 152/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0868 - categorical_accuracy: 0.9745 - val_loss: 1.6652 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00152: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 1.64052\n",
      "Epoch 153/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0981 - categorical_accuracy: 0.9700 - val_loss: 1.6901 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00153: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 1.64052\n",
      "Epoch 154/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0932 - categorical_accuracy: 0.9755 - val_loss: 1.6873 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00154: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 1.64052\n",
      "Epoch 155/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0968 - categorical_accuracy: 0.9715 - val_loss: 1.6898 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00155: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 1.64052\n",
      "Epoch 156/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0938 - categorical_accuracy: 0.9675 - val_loss: 1.6873 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00156: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 1.64052\n",
      "Epoch 157/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0831 - categorical_accuracy: 0.9720 - val_loss: 1.6683 - val_categorical_accuracy: 0.7579\n",
      "\n",
      "Epoch 00157: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 1.64052\n",
      "Epoch 158/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0815 - categorical_accuracy: 0.9745 - val_loss: 1.6310 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00158: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00158: val_loss improved from 1.64052 to 1.63104, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 159/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0737 - categorical_accuracy: 0.9800 - val_loss: 1.6429 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00159: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 1.63104\n",
      "Epoch 160/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0965 - categorical_accuracy: 0.9695 - val_loss: 1.6839 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00160: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 1.63104\n",
      "Epoch 161/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0907 - categorical_accuracy: 0.9685 - val_loss: 1.6856 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00161: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 1.63104\n",
      "Epoch 162/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0951 - categorical_accuracy: 0.9735 - val_loss: 1.6555 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00162: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 1.63104\n",
      "Epoch 163/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0867 - categorical_accuracy: 0.9745 - val_loss: 1.6621 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00163: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 1.63104\n",
      "Epoch 164/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0907 - categorical_accuracy: 0.9740 - val_loss: 1.6851 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00164: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 1.63104\n",
      "Epoch 165/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0923 - categorical_accuracy: 0.9725 - val_loss: 1.6532 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00165: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 1.63104\n",
      "Epoch 166/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0784 - categorical_accuracy: 0.9775 - val_loss: 1.6393 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00166: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 1.63104\n",
      "Epoch 167/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0871 - categorical_accuracy: 0.9760 - val_loss: 1.6643 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00167: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 1.63104\n",
      "Epoch 168/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0709 - categorical_accuracy: 0.9800 - val_loss: 1.6255 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00168: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00168: val_loss improved from 1.63104 to 1.62555, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 169/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0814 - categorical_accuracy: 0.9780 - val_loss: 1.6256 - val_categorical_accuracy: 0.7605\n",
      "\n",
      "Epoch 00169: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 1.62555\n",
      "Epoch 170/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0700 - categorical_accuracy: 0.9775 - val_loss: 1.6158 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00170: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00170: val_loss improved from 1.62555 to 1.61577, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 171/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0729 - categorical_accuracy: 0.9780 - val_loss: 1.6106 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00171: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00171: val_loss improved from 1.61577 to 1.61059, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 172/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0775 - categorical_accuracy: 0.9760 - val_loss: 1.5903 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00172: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00172: val_loss improved from 1.61059 to 1.59035, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 173/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0798 - categorical_accuracy: 0.9765 - val_loss: 1.6088 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00173: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 1.59035\n",
      "Epoch 174/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0854 - categorical_accuracy: 0.9720 - val_loss: 1.5942 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00174: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 1.59035\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0702 - categorical_accuracy: 0.9795 - val_loss: 1.5817 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00175: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00175: val_loss improved from 1.59035 to 1.58170, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 176/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0817 - categorical_accuracy: 0.9790 - val_loss: 1.6110 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00176: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 1.58170\n",
      "Epoch 177/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.1058 - categorical_accuracy: 0.9745 - val_loss: 1.6107 - val_categorical_accuracy: 0.7711\n",
      "\n",
      "Epoch 00177: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 1.58170\n",
      "Epoch 178/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0738 - categorical_accuracy: 0.9755 - val_loss: 1.5975 - val_categorical_accuracy: 0.7684\n",
      "\n",
      "Epoch 00178: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 1.58170\n",
      "Epoch 179/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0816 - categorical_accuracy: 0.9785 - val_loss: 1.6229 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00179: val_categorical_accuracy did not improve from 0.78158\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 1.58170\n",
      "Epoch 180/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0682 - categorical_accuracy: 0.9810 - val_loss: 1.5737 - val_categorical_accuracy: 0.7842\n",
      "\n",
      "Epoch 00180: val_categorical_accuracy improved from 0.78158 to 0.78421, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00180: val_loss improved from 1.58170 to 1.57374, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 181/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0844 - categorical_accuracy: 0.9765 - val_loss: 1.6237 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00181: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 1.57374\n",
      "Epoch 182/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0730 - categorical_accuracy: 0.9740 - val_loss: 1.5979 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00182: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 1.57374\n",
      "Epoch 183/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0741 - categorical_accuracy: 0.9740 - val_loss: 1.6292 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00183: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 1.57374\n",
      "Epoch 184/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0699 - categorical_accuracy: 0.9820 - val_loss: 1.5918 - val_categorical_accuracy: 0.7842\n",
      "\n",
      "Epoch 00184: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 1.57374\n",
      "Epoch 185/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0659 - categorical_accuracy: 0.9820 - val_loss: 1.6158 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00185: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 1.57374\n",
      "Epoch 186/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0841 - categorical_accuracy: 0.9760 - val_loss: 1.6239 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00186: val_categorical_accuracy did not improve from 0.78421\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 1.57374\n",
      "Epoch 187/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0679 - categorical_accuracy: 0.9790 - val_loss: 1.5929 - val_categorical_accuracy: 0.7868\n",
      "\n",
      "Epoch 00187: val_categorical_accuracy improved from 0.78421 to 0.78684, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 1.57374\n",
      "Epoch 188/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0724 - categorical_accuracy: 0.9815 - val_loss: 1.6112 - val_categorical_accuracy: 0.7763\n",
      "\n",
      "Epoch 00188: val_categorical_accuracy did not improve from 0.78684\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 1.57374\n",
      "Epoch 189/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0795 - categorical_accuracy: 0.9740 - val_loss: 1.6097 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00189: val_categorical_accuracy did not improve from 0.78684\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 1.57374\n",
      "Epoch 190/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0648 - categorical_accuracy: 0.9790 - val_loss: 1.6025 - val_categorical_accuracy: 0.7842\n",
      "\n",
      "Epoch 00190: val_categorical_accuracy did not improve from 0.78684\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 1.57374\n",
      "Epoch 191/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0808 - categorical_accuracy: 0.9785 - val_loss: 1.6212 - val_categorical_accuracy: 0.7895\n",
      "\n",
      "Epoch 00191: val_categorical_accuracy improved from 0.78684 to 0.78947, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 1.57374\n",
      "Epoch 192/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0640 - categorical_accuracy: 0.9810 - val_loss: 1.5856 - val_categorical_accuracy: 0.7921\n",
      "\n",
      "Epoch 00192: val_categorical_accuracy improved from 0.78947 to 0.79211, saving model to ./models/images_evaluation/Angelic/best_acc.h5\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 1.57374\n",
      "Epoch 193/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0690 - categorical_accuracy: 0.9800 - val_loss: 1.5821 - val_categorical_accuracy: 0.7895\n",
      "\n",
      "Epoch 00193: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 1.57374\n",
      "Epoch 194/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0647 - categorical_accuracy: 0.9775 - val_loss: 1.5703 - val_categorical_accuracy: 0.7842\n",
      "\n",
      "Epoch 00194: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00194: val_loss improved from 1.57374 to 1.57027, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 195/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0718 - categorical_accuracy: 0.9790 - val_loss: 1.6074 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00195: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 1.57027\n",
      "Epoch 196/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0713 - categorical_accuracy: 0.9810 - val_loss: 1.5670 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00196: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00196: val_loss improved from 1.57027 to 1.56695, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 197/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0825 - categorical_accuracy: 0.9780 - val_loss: 1.5906 - val_categorical_accuracy: 0.7789\n",
      "\n",
      "Epoch 00197: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 1.56695\n",
      "Epoch 198/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0683 - categorical_accuracy: 0.9810 - val_loss: 1.5867 - val_categorical_accuracy: 0.7658\n",
      "\n",
      "Epoch 00198: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 1.56695\n",
      "Epoch 199/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0534 - categorical_accuracy: 0.9830 - val_loss: 1.5623 - val_categorical_accuracy: 0.7737\n",
      "\n",
      "Epoch 00199: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00199: val_loss improved from 1.56695 to 1.56231, saving model to ./models/images_evaluation/Angelic/best_loss.h5\n",
      "Epoch 200/200\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0850 - categorical_accuracy: 0.9785 - val_loss: 1.6017 - val_categorical_accuracy: 0.7816\n",
      "\n",
      "Epoch 00200: val_categorical_accuracy did not improve from 0.79211\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 1.56231\n"
     ]
    }
   ],
   "source": [
    "history = train_convnet(convnet, tg, vg, directory, verbose=True, loss_obj=loss_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "quizzing best accuracy model...\n",
      "\n",
      "Quiz results: 301 out of 380 correct.\n",
      "Quiz accuracy score: 0.792. Error rate: 0.208\n",
      "Classification results: 295 out of 380 correct.\n",
      "Classification accuracy score: 0.776. Error rate: 0.224\n",
      "\n",
      "quizzing best loss model...\n",
      "\n",
      "Quiz results: 294 out of 380 correct.\n",
      "Quiz accuracy score: 0.774. Error rate: 0.226\n",
      "Classification results: 296 out of 380 correct.\n",
      "Classification accuracy score: 0.779. Error rate: 0.221\n",
      "\n",
      "quizzing best overfit model...\n",
      "\n",
      "Quiz results: 297 out of 380 correct.\n",
      "Quiz accuracy score: 0.782. Error rate: 0.218\n",
      "Classification results: 295 out of 380 correct.\n",
      "Classification accuracy score: 0.776. Error rate: 0.224\n"
     ]
    }
   ],
   "source": [
    "results1, results2, results3 = quiz_models(directory, test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/omniglot/capsulelayers.py:137: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "capsnet, eval_model, manipulate_model = make_capsnet(input_shape, n_class, routings, reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.9052 - capsnet_loss: 0.8504 - decoder_loss: 0.1398 - capsnet_acc: 0.1745 - val_loss: 0.8486 - val_capsnet_loss: 0.8100 - val_decoder_loss: 0.0986 - val_capsnet_acc: 0.0447\n",
      "\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.04474, saving model to ./models/images_evaluation/Angelic/best_acc_caps.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.84864, saving model to ./models/images_evaluation/Angelic/best_loss_caps.h5\n",
      "Epoch 2/100\n",
      " 15/100 [===>..........................] - ETA: 2:01 - loss: 0.8426 - capsnet_loss: 0.8100 - decoder_loss: 0.0831 - capsnet_acc: 0.1567"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ef7351eeec3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/omniglot/build_models.py\u001b[0m in \u001b[0;36mtrain_capsnet\u001b[0;34m(model, train_generator, val_generator, directory, verbose, lr, lr_decay)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'overfit_caps.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_tracker = LossTracker()\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=batch_size)\n",
    "history = train_capsnet(capsnet, tg, vg, directory, verbose=True, loss_obj=loss_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_caps1, results_caps2, results_caps3 = quiz_models(directory, test, labels, capsnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
