{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip install Augmentor\n",
    "!pip install pillow\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install keras\n",
    "!pip install scikit-image\n",
    "!unzip ./python/images_background.zip\n",
    "!unzip ./python/images_background_small1.zip\n",
    "!unzip ./python/images_background_small2.zip\n",
    "!unzip ./python/images_evaluation.zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from load_data import load_directory, train_gen, val_gen, quiz_models, LossTracker\n",
    "from build_models import make_convnet, make_capsnet, train_convnet, train_capsnet, plot_history\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers import Input\n",
    "from capsulelayers import Length, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up for Angelic alphabet\n",
    "batch_size = 30\n",
    "alphabet = 'Angelic'\n",
    "directory = './images_evaluation/{}/'.format(alphabet)\n",
    "train, test, labels = load_directory(directory)\n",
    "loss_tracker = LossTracker() #Tracks loss for augmentation schedule.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=len(test)) #Use the entire validation set here.\n",
    "input_shape = (105, 105, 1)\n",
    "n_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set \"width\" 43, results in 24,628,743 parameters.\n",
    "convnet = make_convnet(input_shape, n_class, width=43, dropout=.5)\n",
    "print(convnet.summary())\n",
    "\n",
    "history = train_convnet(convnet, tg, vg, directory, loss_obj=loss_tracker, epochs=2)\n",
    "plot_history(history, model_name='Angelic Convnet')\n",
    "\n",
    "results1_Ang, results2_Ang, results3_Ang = quiz_models(directory, test, labels, visualize=True, train_df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routings = 3\n",
    "reconstruction_loss = .392\n",
    "capsnet, eval_model, manipulate_model = make_capsnet(\n",
    "    input_shape, \n",
    "    n_class, \n",
    "    routings, \n",
    "    reconstruction_loss, \n",
    "    lambda_downweight=.4\n",
    ")\n",
    "print(capsnet.summary())\n",
    "\n",
    "loss_tracker = LossTracker(scale_by=.1) #Advance augmentation schedule. Capsnet is robust to this.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=batch_size)\n",
    "val_steps = len(test)//batch_size\n",
    "history = train_capsnet(capsnet, tg, vg, directory, loss_obj=loss_tracker, validation_steps=val_steps, epochs=2)\n",
    "\n",
    "plot_history(history, model_name='Angelic Capsnet', capsnet=True)\n",
    "\n",
    "results_caps1_Ang, results_caps2_Ang, results_caps3_Ang = quiz_models(\n",
    "    directory, \n",
    "    test, \n",
    "    labels, \n",
    "    capsnet=True, \n",
    "    visualize=True,\n",
    "    eval_model=eval_model,\n",
    "    train_df=train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up for Atemayar Qelisayer alphabet\n",
    "batch_size = 30\n",
    "alphabet = 'Atemayar_Qelisayer'\n",
    "directory = './images_evaluation/{}/'.format(alphabet)\n",
    "train, test, labels = load_directory(directory)\n",
    "loss_tracker = LossTracker() #Tracks loss for augmentation schedule.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=len(test)) #Use the entire validation set here.\n",
    "input_shape = (105, 105, 1)\n",
    "n_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set \"width\" 44, results in 24,700,321 parameters.\n",
    "convnet = make_convnet(input_shape, n_class, width=44, dropout=.5)\n",
    "print(convnet.summary())\n",
    "\n",
    "history = train_convnet(convnet, tg, vg, directory, loss_obj=loss_tracker, epochs=2)\n",
    "plot_history(history, model_name='Atemayar Convnet')\n",
    "\n",
    "results1_Ang, results2_Ang, results3_Ang = quiz_models(directory, test, labels, visualize=True, train_df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routings = 3\n",
    "reconstruction_loss = .392\n",
    "capsnet, eval_model, manipulate_model = make_capsnet(\n",
    "    input_shape, \n",
    "    n_class, \n",
    "    routings, \n",
    "    reconstruction_loss, \n",
    "    lambda_downweight=.35\n",
    ")\n",
    "print(capsnet.summary())\n",
    "\n",
    "loss_tracker = LossTracker(scale_by=.1) #Advance augmentation schedule. Capsnet is robust to this.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=batch_size)\n",
    "val_steps = len(test)//batch_size\n",
    "history = train_capsnet(capsnet, tg, vg, directory, loss_obj=loss_tracker, validation_steps=val_steps, epochs=2)\n",
    "\n",
    "plot_history(history, model_name='Atemayer Capsnet', capsnet=True)\n",
    "\n",
    "results_caps1_Ang, results_caps2_Ang, results_caps3_Ang = quiz_models(\n",
    "    directory, \n",
    "    test, \n",
    "    labels, \n",
    "    capsnet=True, \n",
    "    visualize=True,\n",
    "    eval_model=eval_model,\n",
    "    train_df=train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up for Oriya alphabet\n",
    "batch_size = 30\n",
    "alphabet = 'Oriya'\n",
    "directory = './images_evaluation/{}/'.format(alphabet)\n",
    "train, test, labels = load_directory(directory)\n",
    "loss_tracker = LossTracker() #Tracks loss for augmentation schedule.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=len(test)) #Use the entire validation set here.\n",
    "input_shape = (105, 105, 1)\n",
    "n_class = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set \"width\" 47, results in 24,700,321 parameters.\n",
    "convnet = make_convnet(input_shape, n_class, width=47, dropout=.5)\n",
    "print(convnet.summary())\n",
    "\n",
    "history = train_convnet(convnet, tg, vg, directory, loss_obj=loss_tracker, epochs=2)\n",
    "plot_history(history, model_name='Oriya Convnet')\n",
    "\n",
    "results1_Ang, results2_Ang, results3_Ang = quiz_models(directory, test, labels, visualize=True, train_df=train)\n",
    "\n",
    "routings = 3\n",
    "reconstruction_loss = .392\n",
    "capsnet, eval_model, manipulate_model = make_capsnet(\n",
    "    input_shape, \n",
    "    n_class, \n",
    "    routings, \n",
    "    reconstruction_loss, \n",
    "    lambda_downweight=.3 #lower this number for higher number of classes.\n",
    ")\n",
    "print(capsnet.summary())\n",
    "\n",
    "loss_tracker = LossTracker(scale_by=.1) #Advance augmentation schedule. Capsnet is robust to this.\n",
    "tg = train_gen(train, labels, batch_size=batch_size, augmentation=True, loss_obj=loss_tracker)\n",
    "vg = val_gen(test, labels, batch_size=batch_size)\n",
    "val_steps = len(test)//batch_size\n",
    "history = train_capsnet(capsnet, tg, vg, directory, loss_obj=loss_tracker, validation_steps=val_steps, epochs=2)\n",
    "\n",
    "plot_history(history, model_name='Oriya Capsnet', capsnet=True)\n",
    "\n",
    "results_caps1_Ang, results_caps2_Ang, results_caps3_Ang = quiz_models(\n",
    "    directory, \n",
    "    test, \n",
    "    labels, \n",
    "    capsnet=True, \n",
    "    visualize=True,\n",
    "    eval_model=eval_model,\n",
    "    train_df=train\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev1]",
   "language": "python",
   "name": "conda-env-dev1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
